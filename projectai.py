# -*- coding: utf-8 -*-
"""ProjectAi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WQaLKuBaFf2HMByaSScxJ8tlg9wCS9Bx
"""



#Chronic kidney disease prediction using AI 
#description : This program clasifies patients as having choronic kidney disease (ckd) or not 
#              using Artificical Neural Networks(ANN)



#import libraries
import glob
from keras.models import Sequential, load_model
import numpy as np
import pandas as pd
from keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
import matplotlib.pyplot as plt
import keras as k
import seaborn as sns
sns.set()



#Load the data
from google.colab import files
uploaded = files.upload()

df = pd.read_csv('CKD_Preprocessed.csv')
#Print the first 5 rows
df.head()



#Get the shape of the data (the number of rows & clos)
df.shape
#(769, 25) means we have 400 patients data and 25 points for each patient



#Create a list of column names to keep
columns_to_retain = ['Specific Gravity','Albumin','Serum Creatinine (mgs/dL)','Hemoglobin (gms)','Packed Cell Volume','White Blood Cells (cells/cmm)','Red Blood Cells (millions/cmm)','Hypertension: yes','Chronic Kidney Disease: yes']

#Drop the columns that are not in columns_to_retain
df = df.drop( [col for col in df.columns if not col in columns_to_retain] , axis=1)

#Drop the roes with na or missing values
df = df.dropna(axis=0)



#Transform the non-numeric data in the columns
#for column in df.columns:
 # if df[column].dtype == np.number:
  #  continue
 # df[column] = LabelEncoder().fit_transfore( df[column])



#Print the first 5 rows of the new created dataset
df.head()



#Split the data into independent (x) dataset (the features) and dependent (y) dataset (the target)
x = df.drop(['Chronic Kidney Disease: yes'], axis=1)
y = df['Chronic Kidney Disease: yes']



#Feature Scaling
#min.max scaler method scales the data set to that all the input features lie between 0 and 1
x_scaler = MinMaxScaler()
x_scaler.fit(x)
column_names = x.columns
x[column_names] = x_scaler.transform(x)



#Split the data into 80% training and 20%testing and shuffle
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, shuffle=True)



#Build the model
#sequential model
model = Sequential()
model.add( Dense(256, input_dim= len(x.columns) , kernel_initializer= k.initializers.random_normal(seed=13), activation='relu'))
model.add( Dense(1, activation='hard_sigmoid') )



#Compile the model
model.compile(loss='binary_crossentropy' , optimizer='adam' , metrics=['accuracy'])



#Train the model
history = model.fit(x_train, y_train, epochs = 2500, batch_size= x_train.shape[0])



#Save the model
model.save('ckd.model')



#Visualize the models loss and accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('model accuracy & loss')
plt.ylabel('accuracy and loss')
plt.xlabel('epoch')



#Get the shape of traning and testing data
print('shape of training data:', x_train.shape)
print('shape of test data:', x_test.shape)



#Show the actual and predicated values
pred = model.predict(x_test)
pred = [1 if y>=0.5 else 0 for y in pred]

print('Original : {0}'.format(", ".join(str(x) for x in y_test)))
print('Predicted : {0}'.format(", ".join(str(x) for x in pred)))



# Commented out IPython magic to ensure Python compatibility.
# Import libraries, features and settings (not all of these are needed so pull what you need)

import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import io
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
from sklearn import preprocessing
plt.rc("font", size = 14)
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
sns.set(style="white")
sns.set(style="whitegrid", color_codes = True)



# Built in colab with local data upload

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))



df = pd.read_csv(io.StringIO(uploaded['CKD_Preprocessed.csv'].decode('utf-8')))
df = df[['Specific Gravity','Albumin','Serum Creatinine (mgs/dL)','Hemoglobin (gms)','Packed Cell Volume','White Blood Cells (cells/cmm)','Red Blood Cells (millions/cmm)','Hypertension: yes','Chronic Kidney Disease: yes']] 	

df.head()



# Split data into train test sets

from sklearn.model_selection import train_test_split
trainingSet, testSet = train_test_split(df, test_size=0.2)



# Creating the dataframes for training and test datasets
train_df = trainingSet
test_df = testSet

#Clean the missing values if needed
#train_df = train_df.dropna()
#test_df = test_df.dropna()



#Since the data is already split into Train and Test datasets, load the values into X_train, X_test, y_train, y_test
#X_train = train_df.iloc[:,:-1].values
#y_train = train_df.iloc[:,1].values
#X_test = test_df.iloc[:,:-1].values
#y_test = test_df.iloc[:,1].values

X_train = train_df[['Specific Gravity','Albumin','Serum Creatinine (mgs/dL)','Hemoglobin (gms)','Packed Cell Volume','White Blood Cells (cells/cmm)','Red Blood Cells (millions/cmm)','Hypertension: yes']] 	

y_train = train_df["Chronic Kidney Disease: yes"]

X_test = test_df[['Specific Gravity','Albumin','Serum Creatinine (mgs/dL)','Hemoglobin (gms)','Packed Cell Volume','White Blood Cells (cells/cmm)','Red Blood Cells (millions/cmm)','Hypertension: yes']] 	

y_test = test_df["Chronic Kidney Disease: yes"]



y_test.head()



from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(X_train,y_train)
y_pred = logreg.predict(X_test)



from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix





from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix



# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline



class_names=[0,1] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')



print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test, y_pred))
print("Recall:",metrics.recall_score(y_test, y_pred))



#predict_proba
y_pred_proba = logreg.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()



from sklearn.metrics import accuracy_score
y_pred = [0, 2, 1, 3]
y_true = [0, 1, 2, 3]
accuracy_score(y_true, y_pred)
accuracy_score(y_true, y_pred, normalize=False)



import numpy as np
accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))



import numpy as np
accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))

#from sklearn import datasets
#from sklearn.model_selection import train_test_split
#from sklearn.tree import DecisionTreeClassifier
#from sklearn.metrics import confusion_matrix
#import matplotlib.pyplot as plt

# load the CKD dataset
#ckd = datasets.load_iris()

# split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(ckd.data, ckd.target, test_size=0.3, random_state=42)

# initialize a decision tree classifier with a range of max_depth values
max_depths = range(1, 100)
accuracies = []

for depth in max_depths:
    clf = DecisionTreeClassifier(max_depth=depth)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    conf_matrix = confusion_matrix(y_test, y_pred)
    accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / sum(sum(conf_matrix))
    accuracies.append(accuracy)

# plot the accuracies against the max_depth values
plt.plot(max_depths, accuracies)
plt.xlabel('max_depth')
plt.ylabel('Accuracy:')
plt.title('Accuracy Graph for CKD Classification Using Confusion Matrix')
plt.show()



#accuracy_score
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# load the CKD dataset
ckd = datasets.load_iris()

# split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(ckd.data, ckd.target, test_size=0.3, random_state=42)

# initialize a decision tree classifier with a range of max_depth values
max_depths = range(1, 10)
acc_scores = []

for depth in max_depths:
    clf = DecisionTreeClassifier(max_depth=depth)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    acc_scores.append(acc)

# plot the accuracy scores against the max_depth values
plt.plot(max_depths, acc_scores)
plt.xlabel('max_depth')
plt.ylabel('Accuracy')
plt.title('Accuracy Graph for CKD Classification')
plt.show()



#recall_score
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import recall_score
import matplotlib.pyplot as plt

# load the CKD dataset
ckd = datasets.load_iris()

# split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(ckd.data, ckd.target, test_size=0.3, random_state=42)

# initialize a decision tree classifier with a range of max_depth values
max_depths = range(1, 10)
recall_scores = []

for depth in max_depths:
    clf = DecisionTreeClassifier(max_depth=depth)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    recall = recall_score(y_test, y_pred, average='macro')
    recall_scores.append(recall)

# plot the recall scores against the max_depth values
plt.plot(max_depths, recall_scores)
plt.xlabel('max_depth')
plt.ylabel('Recall')
plt.title('Recall Graph for CKD Classification')
plt.show()



#f1_score
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score
import matplotlib.pyplot as plt

# load the CKD dataset
ckd = datasets.load_iris()

# split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(ckd.data, ckd.target, test_size=0.3, random_state=42)

# initialize a decision tree classifier with a range of max_depth values
max_depths = range(1, 10)
f1_scores = []

for depth in max_depths:
    clf = DecisionTreeClassifier(max_depth=depth)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    f1 = f1_score(y_test, y_pred, average='macro')
    f1_scores.append(f1)

# plot the F1 scores against the max_depth values
plt.plot(max_depths, f1_scores)
plt.xlabel('max_depth')
plt.ylabel('F1 score')
plt.title('F1 Score Graph for CKD Classification')
plt.show()